@article{andrusenko2024fast,
  title={Fast Context-Biasing for CTC and Transducer ASR models with CTC-based Word Spotter},
  author={Andrusenko, Andrei and Laptev, Aleksandr and Bataev, Vladimir and Lavrukhin, Vitaly and Ginsburg, Boris},
  journal={arXiv preprint arXiv:2406.07096},
  year={2024}
}

@article{ardila2019common,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@article{beltagy2020longformer,
  title={Longformer: The long-document transformer},
  author={Beltagy, Iz and Peters, Matthew E and Cohan, Arman},
  journal={arXiv preprint arXiv:2004.05150},
  year={2020}
}

@article{chen2023hyporadise,
  title={Hyporadise: An open baseline for generative speech recognition with large language models},
  author={Chen, Chen and Hu, Yuchen and Yang, Chao-Han Huck and Siniscalchi, Sabato Marco and Chen, Pin-Yu and Chng, Eng-Siong},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  pages={31665--31688},
  year={2023}
}

@article{cherniuk2023run,
  title={Run LoRA Run: Faster and Lighter LoRA Implementations},
  author={Cherniuk, Daria and Mikhalev, Aleksandr and Oseledets, Ivan},
  journal={arXiv preprint arXiv:2312.03415},
  year={2023}
}

@article{chu2023qwen,
  title={Qwen-audio: Advancing universal audio understanding via unified large-scale audio-language models},
  author={Chu, Yunfei and Xu, Jin and Zhou, Xiaohuan and Yang, Qian and Zhang, Shiliang and Yan, Zhijie and Zhou, Chang and Zhou, Jingren},
  journal={arXiv preprint arXiv:2311.07919},
  year={2023}
}

@article{dao2022flashattention,
  title={Flashattention: Fast and memory-efficient exact attention with io-awareness},
  author={Dao, Tri and Fu, Dan and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={16344--16359},
  year={2022}
}

@article{dao2023flashattention,
  title={Flashattention-2: Faster attention with better parallelism and work partitioning},
  author={Dao, Tri},
  journal={arXiv preprint arXiv:2307.08691},
  year={2023}
}

@article{dua2023noise,
  title={Noise robust automatic speech recognition: review and analysis},
  author={Dua, Mohit and Akanksha and Dua, Shelza},
  journal={International Journal of Speech Technology},
  volume={26},
  number={2},
  pages={475--519},
  year={2023},
  publisher={Springer}
}

@article{engstrom2019adversarial,
  title={Adversarial robustness as a prior for learned representations},
  author={Engstrom, Logan and Ilyas, Andrew and Santurkar, Shibani and Tsipras, Dimitris and Tran, Brandon and Madry, Aleksander},
  journal={arXiv preprint arXiv:1906.00945},
  year={2019}
}

@article{freitag2017beam,
  title={Beam search strategies for neural machine translation},
  author={Freitag, Markus and Al-Onaizan, Yaser},
  journal={arXiv preprint arXiv:1702.01806},
  year={2017}
}

@article{goodfellow2014explaining,
  title={Explaining and harnessing adversarial examples},
  author={Goodfellow, Ian J and Shlens, Jonathon and Szegedy, Christian},
  journal={arXiv preprint arXiv:1412.6572},
  year={2014}
}

@article{grattafiori2024llama,
  title={The llama 3 herd of models},
  author={Grattafiori, Aaron and Dubey, Abhimanyu and Jauhri, Abhinav and Pandey, Abhinav and Kadian, Abhishek and Al-Dahle, Ahmad and Letman, Aiesha and Mathur, Akhil and Schelten, Alan and Vaughan, Alex and others},
  journal={arXiv preprint arXiv:2407.21783},
  year={2024}
}

@article{graves2012sequence,
  title={Sequence transduction with recurrent neural networks},
  author={Graves, Alex},
  journal={arXiv preprint arXiv:1211.3711},
  year={2012}
}

@article{gulati2020conformer,
  title={Conformer: Convolution-augmented transformer for speech recognition},
  author={Gulati, Anmol and Qin, James and Chiu, Chung-Cheng and Parmar, Niki and Zhang, Yu and Yu, Jiahui and Han, Wei and Wang, Shibo and Zhang, Zhengdong and Wu, Yonghui and others},
  journal={arXiv preprint arXiv:2005.08100},
  year={2020}
}

@article{hannun2014deep,
  title={Deep speech: Scaling up end-to-end speech recognition},
  author={Hannun, Awni and Case, Carl and Casper, Jared and Catanzaro, Bryan and Diamos, Greg and Elsen, Erich and Prenger, Ryan and Satheesh, Sanjeev and Sengupta, Shubho and Coates, Adam and others},
  journal={arXiv preprint arXiv:1412.5567},
  year={2014}
}

@article{hansen1996analysis,
  title={Analysis and compensation of speech under stress and noise for environmental robustness in speech recognition},
  author={Hansen, John HL},
  journal={Speech communication},
  volume={20},
  number={1-2},
  pages={151--173},
  year={1996},
  publisher={Elsevier}
}

@article{Heideman1984,
  title = {Gauss and the history of the fast fourier transform},
  volume = {1},
  ISSN = {0740-7467},
  url = {http://dx.doi.org/10.1109/MASSP.1984.1162257},
  DOI = {10.1109/massp.1984.1162257},
  number = {4},
  journal = {IEEE ASSP Magazine},
  publisher = {Institute of Electrical and Electronics Engineers (IEEE)},
  author = {Heideman,  M. and Johnson,  D. and Burrus,  C.},
  year = {1984},
  month = oct,
  pages = {14--21}
}

@article{hu2022lora,
  title={Lora: Low-rank adaptation of large language models.},
  author={Hu, Edward J and Shen, Yelong and Wallis, Phillip and Allen-Zhu, Zeyuan and Li, Yuanzhi and Wang, Shean and Wang, Lu and Chen, Weizhu and others},
  journal={ICLR},
  volume={1},
  number={2},
  pages={3},
  year={2022}
}

@article{iudinenhancing,
  title={Enhancing Speech Recognition with LLMs in Post-Correction Settings},
  author={Iudin, Artyom and Korzh, Dmitrii and Skripkin, Matvey and Masnyi, Dmitrii and Rogov, Oleg}
}

@article{jain2023neftune,
  title={Neftune: Noisy embeddings improve instruction finetuning},
  author={Jain, Neel and Chiang, Ping-yeh and Wen, Yuxin and Kirchenbauer, John and Chu, Hong-Min and Somepalli, Gowthami and Bartoldson, Brian R and Kailkhura, Bhavya and Schwarzschild, Avi and Saha, Aniruddha and others},
  journal={arXiv preprint arXiv:2310.05914},
  year={2023}
}

@article{kalamkar2019study,
  title={A study of BFLOAT16 for deep learning training},
  author={Kalamkar, Dhiraj and Mudigere, Dheevatsa and Mellempudi, Naveen and Das, Dipankar and Banerjee, Kunal and Avancha, Sasikanth and Vooturi, Dharma Teja and Jammalamadaka, Nataraj and Huang, Jianyu and Yuen, Hector and others},
  journal={arXiv preprint arXiv:1905.12322},
  year={2019}
}

@article{karpov2021golos,
  title={Golos: Russian dataset for speech research},
  author={Karpov, Nikolay and Denisenko, Alexander and Minkin, Fedor},
  journal={arXiv preprint arXiv:2106.10161},
  year={2021}
}

@article{LeCun1989,
  title = {Backpropagation Applied to Handwritten Zip Code Recognition},
  volume = {1},
  ISSN = {1530-888X},
  url = {http://dx.doi.org/10.1162/neco.1989.1.4.541},
  DOI = {10.1162/neco.1989.1.4.541},
  number = {4},
  journal = {Neural Computation},
  publisher = {MIT Press},
  author = {LeCun,  Y. and Boser,  B. and Denker,  J. S. and Henderson,  D. and Howard,  R. E. and Hubbard,  W. and Jackel,  L. D.},
  year = {1989},
  month = dec,
  pages = {541â€“551}
}

@article{lin2024awq,
  title={Awq: Activation-aware weight quantization for on-device llm compression and acceleration},
  author={Lin, Ji and Tang, Jiaming and Tang, Haotian and Yang, Shang and Chen, Wei-Ming and Wang, Wei-Chen and Xiao, Guangxuan and Dang, Xingyu and Gan, Chuang and Han, Song},
  journal={Proceedings of Machine Learning and Systems},
  volume={6},
  pages={87--100},
  year={2024}
}

@article{madry2017towards,
  title={Towards deep learning models resistant to adversarial attacks},
  author={Madry, Aleksander and Makelov, Aleksandar and Schmidt, Ludwig and Tsipras, Dimitris and Vladu, Adrian},
  journal={arXiv preprint arXiv:1706.06083},
  year={2017}
}

@article{marzal2002computation,
  title={Computation of normalized edit distance and applications},
  author={Marzal, Andres and Vidal, Enrique},
  journal={IEEE transactions on pattern analysis and machine intelligence},
  volume={15},
  number={9},
  pages={926--932},
  year={2002},
  publisher={IEEE}
}

@article{micikevicius2017mixed,
  title={Mixed precision training},
  author={Micikevicius, Paulius and Narang, Sharan and Alben, Jonah and Diamos, Gregory and Elsen, Erich and Garcia, David and Ginsburg, Boris and Houston, Michael and Kuchaiev, Oleksii and Venkatesh, Ganesh and others},
  journal={arXiv preprint arXiv:1710.03740},
  year={2017}
}

@article{olivier2022recent,
  title={Recent improvements of ASR models in the face of adversarial attacks},
  author={Olivier, Raphael and Raj, Bhiksha},
  journal={arXiv preprint arXiv:2203.16536},
  year={2022}
}

@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec and Narasimhan, Karthik and Salimans, Tim and Sutskever, Ilya and others},
  year={2018},
  publisher={San Francisco, CA, USA}
}

@article{radford2019language,
  title={Language models are unsupervised multitask learners},
  author={Radford, Alec and Wu, Jeffrey and Child, Rewon and Luan, David and Amodei, Dario and Sutskever, Ilya and others},
  journal={OpenAI blog},
  volume={1},
  number={8},
  pages={9},
  year={2019}
}

@article{radhakrishnan2023whispering,
  title={Whispering llama: A cross-modal generative error correction framework for speech recognition},
  author={Radhakrishnan, Srijith and Yang, Chao-Han Huck and Khan, Sumeer Ahmad and Kumar, Rohit and Kiani, Narsis A and Gomez-Cabrero, David and Tegner, Jesper N},
  journal={arXiv preprint arXiv:2310.06434},
  year={2023}
}

@article{raffel2020exploring,
  title={Exploring the limits of transfer learning with a unified text-to-text transformer},
  author={Raffel, Colin and Shazeer, Noam and Roberts, Adam and Lee, Katherine and Narang, Sharan and Matena, Michael and Zhou, Yanqi and Li, Wei and Liu, Peter J},
  journal={Journal of machine learning research},
  volume={21},
  number={140},
  pages={1--67},
  year={2020}
}

@article{tang2023salmonn,
  title={Salmonn: Towards generic hearing abilities for large language models},
  author={Tang, Changli and Yu, Wenyi and Sun, Guangzhi and Chen, Xianzhao and Tan, Tian and Li, Wei and Lu, Lu and Ma, Zejun and Zhang, Chao},
  journal={arXiv preprint arXiv:2310.13289},
  year={2023}
}

@article{vaswani2017attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{watanabe2020chime,
  title={CHiME-6 challenge: Tackling multispeaker speech recognition for unsegmented recordings},
  author={Watanabe, Shinji and Mandel, Michael and Barker, Jon and Vincent, Emmanuel and Arora, Ashish and Chang, Xuankai and Khudanpur, Sanjeev and Manohar, Vimal and Povey, Daniel and Raj, Desh and others},
  journal={arXiv preprint arXiv:2004.09249},
  year={2020}
}

@article{xue2020mt5,
  title={mT5: A massively multilingual pre-trained text-to-text transformer},
  author={Xue, Linting and Constant, Noah and Roberts, Adam and Kale, Mihir and Al-Rfou, Rami and Siddhant, Aditya and Barua, Aditya and Raffel, Colin},
  journal={arXiv preprint arXiv:2010.11934},
  year={2020}
}

@article{zmitrovich2023family,
  title={A family of pretrained transformer language models for Russian},
  author={Zmitrovich, Dmitry and Abramov, Alexander and Kalmykov, Andrey and Tikhonova, Maria and Taktasheva, Ekaterina and Astafurov, Danil and Baushenko, Mark and Snegirev, Artem and Kadulin, Vitalii and Markov, Sergey and others},
  journal={arXiv preprint arXiv:2309.10931},
  year={2023}
}

@book{warr2019strengthening,
  title={Strengthening Deep Neural Networks: Making {AI} Less Susceptible to Adversarial Trickery},
  author={Warr, Katy},
  year={2019},
  pages={246},
  edition={1},
  notes={{ISBN}: 978-1492044956},
  lccn={2020301355},
  publisher={O'Reilly Media, Inc.}
}

@inproceedings{andrusenko2020exploration,
  title={Exploration of end-to-end asr for openstt--russian open speech-to-text dataset},
  author={Andrusenko, Andrei and Laptev, Aleksandr and Medennikov, Ivan},
  booktitle={International Conference on Speech and Computer},
  pages={35--44},
  year={2020},
  organization={Springer}
}

@inproceedings{amodei2016deep,
  title={Deep speech 2: End-to-end speech recognition in english and mandarin},
  author={Amodei, Dario and Ananthanarayanan, Sundaram and Anubhai, Rishita and Bai, Jingliang and Battenberg, Eric and Case, Carl and Casper, Jared and Catanzaro, Bryan and Cheng, Qiang and Chen, Guoliang and others},
  booktitle={International conference on machine learning},
  pages={173--182},
  year={2016},
  organization={PMLR}
}

@inproceedings{carlini2018audio,
  title={Audio adversarial examples: Targeted attacks on speech-to-text},
  author={Carlini, Nicholas and Wagner, David},
  booktitle={2018 IEEE security and privacy workshops (SPW)},
  pages={1--7},
  year={2018},
  organization={IEEE}
}

@inproceedings{chan2016listen,
  title={Listen, attend and spell: A neural network for large vocabulary conversational speech recognition},
  author={Chan, William and Jaitly, Navdeep and Le, Quoc and Vinyals, Oriol},
  booktitle={2016 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4960--4964},
  year={2016},
  organization={IEEE}
}

@inproceedings{devlin2019bert,
  title={Bert: Pre-training of deep bidirectional transformers for language understanding},
  author={Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
  booktitle={Proceedings of the 2019 conference of the North American chapter of the association for computational linguistics: human language technologies, volume 1 (long and short papers)},
  pages={4171--4186},
  year={2019}
}

@inproceedings{fiscus1997post,
  title={A post-processing system to yield reduced word error rates: Recognizer output voting error reduction (ROVER)},
  author={Fiscus, Jonathan G},
  booktitle={1997 IEEE workshop on automatic speech recognition and understanding proceedings},
  pages={347--354},
  year={1997},
  organization={IEEE}
}

@inproceedings{graves2006connectionist,
  title={Connectionist temporal classification: labelling unsegmented sequence data with recurrent neural networks},
  author={Graves, Alex and Fern{\'a}ndez, Santiago and Gomez, Faustino and Schmidhuber, J{\"u}rgen},
  booktitle={Proceedings of the 23rd international conference on Machine learning},
  pages={369--376},
  year={2006}
}

@inproceedings{heafield2011kenlm,
  title={KenLM: Faster and smaller language model queries},
  author={Heafield, Kenneth},
  booktitle={Proceedings of the sixth workshop on statistical machine translation},
  pages={187--197},
  year={2011}
}

@inproceedings{hu2024large,
  title={Large Language Models are Efficient Learners of Noise-Robust Speech Recognition},
  author={Hu, Yuchen and Chen, Chen and Yang, Chao-Han Huck and Li, Ruizhe and Zhang, Chao and Chen, Pin-Yu and Chng, Eng Siong},
  booktitle={International Conference on Learning Representations},
  year={2024}
}

@inproceedings{levenshtein1966binary,
  title={Binary codes capable of correcting deletions, insertions, and reversals},
  author={Levenshtein, Vladimir I and others},
  booktitle={Soviet physics doklady},
  volume={10},
  number={8},
  pages={707--710},
  year={1966},
  organization={Soviet Union}
}

@inproceedings{lei2023acoustic,
  title={Acoustic model fusion for end-to-end speech recognition},
  author={Lei, Zhihong and Xu, Mingbin and Han, Shiyi and Liu, Leo and Huang, Zhen and Ng, Tim and Zhang, Yuanyuan and Pusateri, Ernest and Hannemann, Mirko and Deng, Yaqiao and others},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--7},
  year={2023},
  organization={IEEE}
}

@inproceedings{li2022blip,
  title={Blip: Bootstrapping language-image pre-training for unified vision-language understanding and generation},
  author={Li, Junnan and Li, Dongxu and Xiong, Caiming and Hoi, Steven},
  booktitle={International conference on machine learning},
  pages={12888--12900},
  year={2022},
  organization={PMLR}
}

@inproceedings{niessen2000evaluation,
  title={An Evaluation Tool for Machine Translation: Fast Evaluation for MT Research.},
  author={Nie{\ss}en, Sonja and Och, Franz Josef and Leusch, Gregor and Ney, Hermann and others},
  booktitle={LREC},
  year={2000}
}

@inproceedings{panayotov2015librispeech,
  title={Librispeech: an asr corpus based on public domain audio books},
  author={Panayotov, Vassil and Chen, Guoguo and Povey, Daniel and Khudanpur, Sanjeev},
  booktitle={2015 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={5206--5210},
  year={2015},
  organization={IEEE}
}

@inproceedings{povey2011kaldi,
  title={The Kaldi speech recognition toolkit},
  author={Povey, Daniel and Ghoshal, Arnab and Boulianne, Gilles and Burget, Lukas and Glembek, Ondrej and Goel, Nagendra and Hannemann, Mirko and Motlicek, Petr and Qian, Yanmin and Schwarz, Petr and others},
  booktitle={IEEE 2011 workshop on automatic speech recognition and understanding},
  year={2011},
  organization={IEEE Signal Processing Society}
}

@inproceedings{radford2021learning,
  title={Learning transferable visual models from natural language supervision},
  author={Radford, Alec and Kim, Jong Wook and Hallacy, Chris and Ramesh, Aditya and Goh, Gabriel and Agarwal, Sandhini and Sastry, Girish and Askell, Amanda and Mishkin, Pamela and Clark, Jack and others},
  booktitle={International conference on machine learning},
  pages={8748--8763},
  year={2021},
  organization={PmLR}
}

@inproceedings{radford2023robust,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International conference on machine learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@inproceedings{rekesh2023fast,
  title={Fast conformer with linearly scalable attention for efficient speech recognition},
  author={Rekesh, Dima and Koluguri, Nithin Rao and Kriman, Samuel and Majumdar, Somshubra and Noroozi, Vahid and Huang, He and Hrinchuk, Oleksii and Puvvada, Krishna and Kumar, Ankur and Balam, Jagadeesh and others},
  booktitle={2023 IEEE Automatic Speech Recognition and Understanding Workshop (ASRU)},
  pages={1--8},
  year={2023},
  organization={IEEE}
}

@inproceedings{toshniwal2018comparison,
  title={A comparison of techniques for language model integration in encoder-decoder speech recognition},
  author={Toshniwal, Shubham and Kannan, Anjuli and Chiu, Chung-Cheng and Wu, Yonghui and Sainath, Tara N and Livescu, Karen},
  booktitle={2018 IEEE spoken language technology workshop (SLT)},
  pages={369--375},
  year={2018},
  organization={IEEE}
}

@inproceedings{yang2024large,
  title={Large language model based generative error correction: A challenge and baselines for speech recognition, speaker tagging, and emotion recognition},
  author={Yang, Chao-Han Huck and Park, Taejin and Gong, Yuan and Li, Yuanchao and Chen, Zhehuai and Lin, Yen-Ting and Chen, Chen and Hu, Yuchen and Dhawan, Kunal and {\.Z}elasko, Piotr and others},
  booktitle={2024 IEEE Spoken Language Technology Workshop (SLT)},
  pages={371--378},
  year={2024},
  organization={IEEE}
}

@misc{sova2021rudevices,
  author = {Zubarev, Egor and Moskalets, Timofey and SOVA.ai},
  title = {SOVA RuDevices Dataset: free public STT/ASR dataset with manually annotated live speech},
  publisher = {GitHub},
  journal = {GitHub repository},
  year = {2021},
  howpublished = {\url{https://github.com/sovaai/sova-dataset}},
}

@inproceedings{zhang2022adversarial,
  title={Adversarial example attacks against asr systems: An overview},
  author={Zhang, Xiao and Tan, Hao and Huang, Xuan and Zhang, Denghui and Tang, Keke and Gu, Zhaoquan},
  booktitle={2022 7th IEEE International Conference on Data Science in Cyberspace (DSC)},
  pages={470--477},
  year={2022},
  organization={IEEE}
}