\newpage
\begin{center}
  \textbf{\large 2. СРАВНЕНИЕ КАЧЕСТВА РАБОТЫ СУЩЕСТВУЮЩИХ МЕТОДОВ}
\end{center}
\refstepcounter{chapter}
\addcontentsline{toc}{chapter}{2. СРАВНЕНИЕ КАЧЕСТВА РАБОТЫ СУЩЕСТВУЮЩИХ МЕТОДОВ}

\section{Данные для обучения}

Немаловажной частью для области машинного обучения являются данные, на которых это всё обучается и оценивается.
Существует огромное количество самых различных датасетов, которые содержат аудио записи, относящиеся  к разным тематикам.
Поговорим сначала об английских.

\texttt{LibriSpeech} какое-то время был самым большим и разнообразным набором данных.
Он содержит в себе озвученные профессиональными спикерами адуиокниги.
Существуют вариации разбиения на 100, 360 и 500 часов.
Также датасет разбивается на clean и other.
Первый проще для распознавания речи, второй сложнее.

\texttt{Common Voice} на данный момент крупнейший датасет и самый популярный набор данных.
Это датасет, который собирается и проверяется силами волонтёров по всему миру.
Каждый человек после регистрации может  внести свой вклад несколькими способами:
\begin{itemize}
  \item Пожертвовать фразу для озвучивания с указанием источника, например книги, газеты и так далее.
    Или же условные фразеологизмы.
  \item Озвучить фразы из общего пула, которые выбираются случайным образом.
  \item Проверить фразы на правописание.
  \item Проверить качество озвучки фраз, чтобы отбросить сгенерированные или плохо озвученные.
\end{itemize}
Весь набор данных хостится при поддержке Mozilla и предоставляется бесплатно при соглашение на условия.
За счёт помощи волонтёров датасет содержит разнообразные темы, а также сотни вариантов произношения.
Такое множество вариантов позволит оценить общую точность работы моделей и подходов.

Эти датасеты являются наиболее разнообразными по темам и набору спикеров, поэтому оценка качества распознавания для английского языка в основном проводится для них.

Для русского языка существуют свои русские версии вышеупомянутых \texttt{LibriSpeech} и \texttt{Common Voice}.
Также существуют несколько датасетов, собранных чисто для русского языка. 
Например, \texttt{DUSHA}.

Мы выберем 21 версию Common Voice (последнюю на момент написания) для русского языка.
Дополнительно мы оставим только верифицированные аудиозаписи, чтобы отбросить потенциально плохие данные.

\section{Выбор моделей}
В качестве основных моделей для тестирования мы определим Fastconformer от Nvidia, обученный для русского языка и Whisper Large от OpenAI, упомянутые в первой главе.
Почему эти две модели? Основная причина – их непохожесть.
Обе модели построенны на разных архитектурах, имеют отличие в размерах в 10 раз, одна является заточенной под один язык, а другая мультиязычной.
Использование именно этих двух моделей позволит сравнить работу некоторых методов на двух моделях сразу, а также далее в 3 главе позволит проверить идею переноса способности к коррекции ошибок между настолько разными моделями.
Также преимуществом именно этих двух моделей являются обширная документация, которая поможет в проведение опытов, и наличие большой базы пользователей, которая разбирала ошибки и также проводила свои эксперименты.
Ну третьим преимуществом является то, что данные модели выпускались более полутора лет назад, а значит они гарантированно не видели части данных из нашего датасета.

В качестве способов улучшения качества мы используем BeamSearch декодирование и рескоринг с помощью языковой модели.
Мы используем n-gram модель, обученной с помощью KenLM как языковую модель.
Преимуществом в нашем случае является то, что достаточно легко можно найти гайд на обучение и на интеграцию модели с Fastconformer.
В качестве текстового набора данных мы используем русский сплит mc4 датасета, который содержит большой набор данных, собраный с интернета парсерами.
Гиперпараметр количества n-граммов мы укажем равным 4.

\begin{table}[]
\centering
\caption{Сравнение значений WER среди существующих базовых методов. ruT5 модель была натренирована на CV21 и RuLS.}
\begin{tabular}{|c|c|ccc|}
\hline
\multirow{2}{*}{Модель}        & \multirow{2}{*}{Сеттинг}             & \multicolumn{3}{c|}{Датасет, WER}                                    \\ \cline{3-5} 
                               &                                      & \multicolumn{1}{c|}{CV21}  & \multicolumn{1}{c|}{RuLS}     & OpenSTT \\ \hline
\multirow{4}{*}{Fastconformer} & Greedy                               & \multicolumn{1}{c|}{12.31} & \multicolumn{1}{c|}{38.43}    & -       \\ \cline{2-5} 
                               & BeamSearch                           & \multicolumn{1}{c|}{12.26} & \multicolumn{1}{c|}{38.84}    & -       \\ \cline{2-5}
                               & ROVER                                & \multicolumn{1}{c|}{-} & \multicolumn{1}{c|}{38.84}    & -       \\ \cline{2-5}
                               & LM                                   & \multicolumn{1}{c|}{9.87}  & \multicolumn{1}{c|}{-}    & -       \\ \hline 
\multirow{3}{*}{Whisper}       & Greedy                               & \multicolumn{1}{c|}{19.60} & \multicolumn{1}{c|}{-}    & -       \\ \cline{2-5} 
                               & ROVER                                & \multicolumn{1}{c|}{-} & \multicolumn{1}{c|}{-}    & -       \\ \cline{2-5}
                               & BeamSearch                           & \multicolumn{1}{c|}{18.33} & \multicolumn{1}{c|}{35.49}    & -       \\ \hline
                               
\end{tabular}
\label{tab:res_comp}
\end{table}

Как мы видим в Таблице~\ref{tab:res_comp}, только LM принесла прирост в качестве на наших данных, уменьшив WER на 20\%.
BeamSearch отработал с приростом на Common Voice, но на RuLibriSpeech значение ошибки выросло.
Также, несмотря на то, что модель Fastconformer была заточена под распознавания только русского языка, но на RuLibrispeech модель показала себя незначительно хуже в сравнение c моделью Whisper от OpenAI.
Хотя на том же CV 21 модель Nvidia показывает себя лучше, несмотря на разницу в 10 раз в количестве параметров.

Подводя итог главы, языковая модель, заточенная исключительно под одну модель распознавания речи, показывает значительный прирост.
Посмотрим, сможет ли универсальный метод превзойти узконаправленный как Whisper превзошёл Fastconformer на RuLibriSpeech.