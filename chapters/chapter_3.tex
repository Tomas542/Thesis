\newpage
\begin{center}
  \textbf{\large 3. РАЗРАБОТКА СОБСТВЕННОГО МЕТОДА}
\end{center}
\refstepcounter{chapter}
\addcontentsline{toc}{chapter}{3. РАЗРАБОТКА СОБСТВЕННОГО МЕТОДА}

Наша основная идея в обучение языковой модели на русском языке для исправление ошибок.
Как мы обсуждали ранее, в основном методы, завязанные на LM полагаются на скрытое представление ASR модели или же на её проекцию в скрытое представление языковой модели.
Мы же будем проводить наши тесты с использованием естественного языка.
То есть мы будем сначала транскрибировать аудио в текст и только потом его править.
Таким образом мы решим проблему универсальности подхода и независимости ASR-LM пары.

\section{Генерация датасета}
Теперь необходимо создать датасет для обучения.
Для этого возьмём и сгенерируем 5 гипотез с помощью BeamSearch метода.
Затем мы подадим все 5 гипотез в нашу модель и попросим сгенерировать исправленную последовательность.

Почему подавать 5 гипотез в модель? Что мы можем взять из гипотез?
Почему просто не реранжировать гипотезы?
Давайте проанализируем полученные данные.

\textbf{Тут графки.}

Сначала разъясним, почему не реранжирование.
Первый график на Рис. 1 показывает процент случаев, когда гипотеза 2-5 имеют ниже WER, чем 1 гипотеза.
Их процент колеблется от 4 до 8, что значит мы можем не получить значительного прироста.
Второй график же показывает процент токенов, которые:
\begin{itemize}
  \item Есть в праильной транскрипции.
  \item Есть в гипотезе $n_k$ и нет в гипотезах $n_i$, где $i < k$.
\end{itemize}

Это та самая информация, которую наша модель может извлечь из сгенерированных гипотез и улучшить качество транскрипции.
Именно поэтом мы переходим к обучению отдельной языковой модели на ошибках.

\section{Описание моделей и процесса обучения}

\textcolor{red}{Архитектуру T5 сюда}

T5 (Text-to-Text Transfer Transformer) -- это универсальная трансформерная модель, разработанная Google Research, которая переформулирует все задачи обработки естественного языка в единый формат Sequence-to-Sequence (Seq2Seq).
Её ключевая особенность -- подход, при котором задачи классификация, перевода, суммаризации и др. представляются как преобразование входной текстовой строки в выходную.

Модель использует энкодер-декодер структуру, где:
\begin{itemize}
  \item Энкодер обрабатывает входной текст, создавая контекстуализированные представления для каждого токена.
  В отличие от чисто декодерных моделей типа GPT, T5 использует двунаправленное внимание, что позволяет анализировать весь входной текст одновременно.
  \item Декодер генерирует выход последовательно, используя авторегрессионный механизм.
  При этом он учитывает скрытые состояния энкодера через кросс-внимание.
  Схожим образом работает ранее упомянутый Whisper.
\end{itemize}

Универсальность подхода Seq2Seq позволяет применять одну и ту же модель для десятков задач без изменения архитектуры.

В качестве двух моделей мы возьмём ruT5 и Fred-T5.
Обе модели были обучены Сбером на корпусе русского языка.
Они построены на архитектуре энкодер-декодер трансформеров.
Их мы выбрали по нескольким причинам:

\begin{enumerate}
  \item \textbf{Размер}.
  Мы берём Base (220М) и distil (95М) версии соответственно. 
  В паре с FastConformer это займёт немногим больше 3 Гб видеопамяти, что позволит влезть в любую пользовательскую видеокарту.
  \item \textbf{Архитектура}.
  Энкодер-декодер лучше улавливает ошибки и корректирует их.
  Такие выводы были сделаны на основе решения этой задачи для английского языка, где в качестве моделей-корректоров использовались Mistral-7b и Llama3-8b.
  На русском они также показывают плохие результаты, поэтому включены они не были.
\end{enumerate}

Обучение ruT5 будет проходить в few-shot сценарии, когда мы ей будем показывать 3 примера из валидационной выборке в качестве примера для улучшения.
Few-shot -- это подход, при котором языковая модель решает новую задачу, используя несколько демонстрационных примеров.
Математически это можно выразить как~\ref{eq:shot}:

\begin{equation}
  P(y_{test}|x_{test},\{x_i,y_i\}^K_{i=1}) = \prod_{t=1}^{T}P(w_t|w_{<t},x_{test},\{(x_i,y_i)\}^K_{i=1},\theta)
  \label{eq:shot}
\end{equation}
где $w_t$ - t-й токен ответа, $\theta$ - параметры модели, а $T$ - длина ответа.

Так мы проведём 15 обучающих эпох и сохраним модель с наименьшим WER на валидационной выборке.
Дополнительн мы используем метод Low-rank adaptaion (LoRA).
Это метод, при котором изначальные веса модели в выбранных слоях замораживаются и никак не изменяются в ходе дообучения.
В нашем случае такими слоями будут слои attention.
У каждой матрицы attention (Q, K, V, O) инициализируется своя пара матриц A и B размерами (h, rank) и (rank, h), где h – размер скрытого пространства матрицы attention, а rank – размер ранга, заданный при LoRA.
Во время обучения будут изменяться как раз матрицы A и B, которые как бы представляют собой сжатую информацию из весов слоя.
Преимуществом LoRA является то, что мы значительно экономим в используемой памяти, жертвуя качеством.
Это происходит благодаря тому, что в state оптимизатора хранятся не матрицы размера h $\times$ h, а две матрицы размеров h $\times$ rank и rank $\times$ h.
Баланс между памятью и качеством достигается за счёт настройки параметра ранга для LoRA.
Чем больше это значение, тем более точное представление изначального слоя мы получаем, но вместе с тем больше памяти будет храниться в state оптимизатора.
С формулой можно ознакомиться в уравнение~\ref{eq:lora}
\begin{equation}
  W_{new} = W_{frozen} + A \times B
  \label{eq:lora}
\end{equation}

Использовался линейный планировщик с периодом разогрева.
Также стоит сказать, что модель обучалась исключительно на ошибках FastConformer модели.
Соответственно результаты для модели Whisper в связке с ruT5 будут показывать результат переноса способностей к коррекции между разными моделями в рамках одного набора данных.

Помимо обученного T5 мы применяли Fred-T5 дистилированный, который используется как инструмент для восстановления знаком препинания.
Это сделано для проверки способностей ASR моделей генерировать последовательности правильные с точки зрения пунктуации.

Итоговую схему пайплайна можно изобразить как на Рис.~\ref{fig:approach}

\begin{figure}[!t]
  \centering
  \includegraphics[width=80mm]{approach.pdf}
  \caption{Итоговая схема пайплайна.}
  \label{fig:approach}
\end{figure}

\section{Результаты}

\begin{table}[]
\centering
\caption{Сравнение значений WER. ruT5 модель была натренирована на CV21 и RuLS}
\begin{tabular}{|c|c|ccc|}
\hline
\multirow{2}{*}{Модель}        & \multirow{2}{*}{Сеттинг}             & \multicolumn{3}{c|}{Датасет, WER}                                    \\ \cline{3-5} 
                               &                                      & \multicolumn{1}{c|}{CV21}  & \multicolumn{1}{c|}{RuLS}     & OpenSTT \\ \hline
\multirow{6}{*}{FastConformer} & Greedy                               & \multicolumn{1}{c|}{12.31} & \multicolumn{1}{c|}{38.43}    & 25.13   \\ \cline{2-5} 
                               & BeamSearch                           & \multicolumn{1}{c|}{12.26} & \multicolumn{1}{c|}{38.84}    & 25.07   \\ \cline{2-5} 
                               & LM                                   & \multicolumn{1}{c|}{9.87}  & \multicolumn{1}{c|}{40.18}    & 27.28   \\ \cline{2-5} 
                               & Greedy+Distill                       & \multicolumn{1}{c|}{13.81} & \multicolumn{1}{c|}{42.16}    & -       \\ \cline{2-5} 
                               & BeamSearch+Distill                   & \multicolumn{1}{c|}{3.82}  & \multicolumn{1}{c|}{42.10}    & -       \\ \cline{2-5} 
                               & BeamSearch+ruT5                      & \multicolumn{1}{c|}{9.75}  & \multicolumn{1}{c|}{34.32}    & 23.81   \\ \hline
\multirow{4}{*}{Whisper}       & Greedy                               & \multicolumn{1}{c|}{19.60} & \multicolumn{1}{c|}{37.89}    & 24.38       \\ \cline{2-5} 
                               & BeamSearch                           & \multicolumn{1}{c|}{18.33} & \multicolumn{1}{c|}{35.49}    & 24.19   \\ \cline{2-5} 
                               & Greedy+Distill                       & \multicolumn{1}{c|}{20.57} & \multicolumn{1}{c|}{41.40}    & -       \\ \cline{2-5} 
                               & BeamSearch+ruT5                      & \multicolumn{1}{c|}{14.32} & \multicolumn{1}{c|}{32.48}    & 23.90   \\ \hline
\end{tabular}
\label{tab:res_full}
\end{table}

Проанализируем результаты Таблицы~\ref{tab:res_full}.


\begin{table}[]
\centering
\caption{Сравнение значений WER. ruT5 модель была натренирована исключительно на CV21.}
\begin{tabular}{|c|c|ccc|}
\hline
\multirow{2}{*}{Модель}        & \multirow{2}{*}{Сеттинг}             & \multicolumn{3}{c|}{Датасет, WER}                                    \\ \cline{3-5} 
                               &                                      & \multicolumn{1}{c|}{CV21}  & \multicolumn{1}{c|}{RuLS}     & OpenSTT \\ \hline
\multirow{2}{*}{FastConformer} & BeamSearch                           & \multicolumn{1}{c|}{12.26} & \multicolumn{1}{c|}{38.34}    & 25.07   \\ \cline{2-5} 
                               & BeamSearch+ruT5                      & \multicolumn{1}{c|}{3.20}  & \multicolumn{1}{c|}{40.07}    & 23.38   \\ \hline
\multirow{2}{*}{Whisper}       & BeamSearch                           & \multicolumn{1}{c|}{18.33} & \multicolumn{1}{c|}{35.49}    & 24.19   \\ \cline{2-5} 
                               & BeamSearch+ruT5                      & \multicolumn{1}{c|}{4.99}  & \multicolumn{1}{c|}{38.04}    & 23.90       \\ \hline
\end{tabular}
\label{tab:res_cv_trained}
\end{table}

Взглянув на Таблицу~\ref{tab:res_cv_trained}, мы можем сделать несколько выводов.
Во-первых — подход с коррекцией текстовой расшифровки аудио показывает себя лучше всех.
Это значит, что богатые лингвистические знания модели + дообучение под нашу задачу работают отлично.
Во-вторых можно увидеть, что перенос знаний между разными ASR моделями также работает.
Так наша модель смогла в 4 раза улучшить качество распознавания для Whisper, хотя до этого она обучалась исключительно на результатах FastConformer.
Также в обоих случаях использование дистиллированной модели при сценарии жадного декодирования не принесло никакого прироста в качестве, а наоборот показало ухудшение. Причин такого падения назвать наверняка нельзя.
Можно сказать, что ASR модели, используя свои знания о языке, имеют более точное представление о правописание и пунктуации.
Или же distill модель пыталась поменять какое-то слово, которое в изменение не нуждалось, из-за чего WER вырос.

\textcolor{red}{ТАБЛИЦА С ГЕНЕРАЦИЯМИ ЧЕРИПИКНИ}

\section{Ограничения}

Мы зависим от качества распознавания ASR.
Для оценки влияния, мы намерено атаковали Whisper с помощью Projection Gradient Descent (PGD).
Это итеративный метод оптимизации, применяемый для задач с ограничениями на параметры.
Он сочетает идеи градиентного спуска с проекцией на допустимое множество.
Он является одним из самых популярных методов white-box атак на модели, то есть видов воздействия, когда у нас есть доступ к выходу модели и её архитектуре.

PGD расширяет классический градиентный спуск, добавляя шаг проекции после каждого обновления параметров.
Если градиентный спуск просто двигается в направлении антиградиента, то PGD дополнительно "проецирует" новую точку обратно на допустимое множество, если та вышла за его пределы. Это позволяет контролировать свойства модели, такие как устойчивость к атакам или физическую осмысленность параметров.
PGD решает задачу атаки итеративно, комбинируя градиентный подъём (для увеличения потерь) и проекцию (для соблюдения ограничений).
Таким образом генерируется шум на аудио.

\begin{table}[]
\centering
\caption{Эксперимент с Projected Gradient Descent white-box атакой на модель Whisper.}
\begin{tabular}{|c|c|c|}
\hline
Модель                         & Сеттинг                              & WER     \\ \hline
\multirow{2}{*}{Whisper}       & BeamSearch                           & 24.48   \\ \cline{2-3} 
                               & BeamSearch+ruT5                      & 21.34   \\ \hline
\end{tabular}
\label{tab:pgd}
\end{table}

\section{Дополнительные эксперименты}

\begin{table}[]
\centering
\caption{Эксперимент с аугментированием гипотез с целью улучшить качество генерации.}
\begin{tabular}{|c|c|c|}
\hline
Модель                         & Сеттинг                              & WER     \\ \hline
\multirow{3}{*}{FastConformer} & BeamSearch                           & 12.26   \\ \cline{2-3} 
                               & BeamSearch+ruT5 (neft)               & 169.94  \\ \cline{2-3} 
                               & BeamSearch+ruT5 (aug)                & 71.42   \\ \hline
\multirow{3}{*}{Whisper}       & BeamSearch                           & 18.33   \\ \cline{2-3} 
                               & BeamSearch+ruT5 (neft)               & 168.90  \\ \cline{2-3} 
                               & BeamSearch+ruT5 (aug)                & 79.52   \\ \hline
\end{tabular}
\label{tab:fails}
\end{table}

\section{Анализ производительности}
По итогу можно уверенно сказать, что наш метод показал в разы лучшее качество в сравнение с другими методами и при этом затраты вычислительных ресурсов, требуемых для inference пары FastConformer + ruT5 сравнительно не велико.
В сумме обе эти модели помещаются в 3-4 Гб видеопамяти, что в современном мире является минимумом для самых низкобюджетных карт, в том числе и среди ноутбучных.

\section{Выводы}
